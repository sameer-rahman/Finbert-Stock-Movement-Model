{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6108e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dateutil.parser import parse\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/raw\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57592c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import raw news data\n",
    "news_df = pd.read_csv(\"data/raw/sp500_news_290k_articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357dcb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_parse_date(x):\n",
    "    try:\n",
    "        dt = parse(x)\n",
    "        return dt.replace(tzinfo=None)\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "# Apply safe, timezone-free parsing across column\n",
    "news_df[\"date\"] = news_df[\"date\"].astype(str).apply(safe_parse_date)\n",
    "\n",
    "# Drop invalid dates\n",
    "news_df = news_df.dropna(subset=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e778a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean ticker data and drop empty columns\n",
    "news_df[\"ticker\"] = news_df[\"ticker\"].str.upper()\n",
    "news_df = news_df.dropna(subset=[\"date\", \"headline\", \"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab9f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the news headlines by ticker and date\n",
    "grouped = news_df.groupby([\"date\", \"ticker\"]).agg({\n",
    "    \"headline\": lambda x: \" \".join(x),\n",
    "    \"compound\": \"mean\"\n",
    "}).reset_index()\n",
    "grouped.rename(columns={\n",
    "    \"headline\": \"combined_headlines\",\n",
    "    \"compound\": \"avg_sentiment\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e77526f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>combined_headlines</th>\n",
       "      <th>avg_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>L</td>\n",
       "      <td>Cordish Cos. leader confident in office projec...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>L</td>\n",
       "      <td>Despite Its High P/E Ratio, Is Loews Corporati...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>L</td>\n",
       "      <td>Loews Corporation to Release Fourth Quarter 20...</td>\n",
       "      <td>0.354325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>L</td>\n",
       "      <td>Altium Packaging, LLC -- Moody's assigns Altiu...</td>\n",
       "      <td>0.378950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>L</td>\n",
       "      <td>Loews (L) Q4 Earnings Beat Estimates, Revenues...</td>\n",
       "      <td>0.236487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date ticker                                 combined_headlines  \\\n",
       "0 2019-12-19      L  Cordish Cos. leader confident in office projec...   \n",
       "1 2020-01-02      L  Despite Its High P/E Ratio, Is Loews Corporati...   \n",
       "2 2020-01-22      L  Loews Corporation to Release Fourth Quarter 20...   \n",
       "3 2020-02-07      L  Altium Packaging, LLC -- Moody's assigns Altiu...   \n",
       "4 2020-02-10      L  Loews (L) Q4 Earnings Beat Estimates, Revenues...   \n",
       "\n",
       "   avg_sentiment  \n",
       "0       0.000000  \n",
       "1       0.000000  \n",
       "2       0.354325  \n",
       "3       0.378950  \n",
       "4       0.236487  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c746a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the aggregated news headlines into its own csv file\n",
    "grouped.to_csv(\"data/raw/news_aggregated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c426a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the aggregated news data and group the \n",
    "news_grouped = pd.read_csv(\"data/raw/news_aggregated.csv\")\n",
    "tickers = news_grouped[\"ticker\"].unique().tolist()\n",
    "tickers = [ticker for ticker in tickers if isinstance(ticker, str) and ticker.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the price data for all the tickers in the aggregated headlines file\n",
    "def get_price_data(ticker, start=\"2019-12-01\", end=\"2023-03-05\"):\n",
    "    try:\n",
    "        df = yf.Ticker(ticker).history(start=start, end=end)\n",
    "        if df.empty:\n",
    "            return None\n",
    "        df = df.reset_index()\n",
    "        df[\"ticker\"] = ticker\n",
    "        return df[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"ticker\"]]\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {ticker}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f24b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/496 [00:02<01:39,  4.90it/s]$RE: possibly delisted; no timezone found\n",
      "  3%|▎         | 15/496 [00:03<01:28,  5.41it/s]$PEAK: possibly delisted; no timezone found\n",
      "  4%|▍         | 21/496 [00:04<01:41,  4.66it/s]$WRK: possibly delisted; no timezone found\n",
      "  6%|▌         | 28/496 [00:05<01:29,  5.23it/s]$FLT: possibly delisted; no timezone found\n",
      "  9%|▉         | 44/496 [00:08<01:27,  5.19it/s]$DRE: possibly delisted; no timezone found\n",
      "  9%|▉         | 45/496 [00:09<01:26,  5.21it/s]$ABMD: possibly delisted; no timezone found\n",
      "  9%|▉         | 47/496 [00:09<01:44,  4.30it/s]$FBHS: possibly delisted; no timezone found\n",
      " 13%|█▎        | 64/496 [00:13<01:24,  5.09it/s]$FRC: possibly delisted; no price data found  (1d 2019-12-01 -> 2023-03-05)\n",
      " 13%|█▎        | 66/496 [00:13<01:07,  6.39it/s]$PBCT: possibly delisted; no timezone found\n",
      " 23%|██▎       | 116/496 [00:25<01:13,  5.15it/s]$NLSN: possibly delisted; no price data found  (1d 2019-12-01 -> 2023-03-05)\n",
      " 27%|██▋       | 135/496 [00:29<01:10,  5.15it/s]$ABC: possibly delisted; no timezone found\n",
      " 28%|██▊       | 137/496 [00:29<01:07,  5.34it/s]$HFC: possibly delisted; no timezone found\n",
      " 28%|██▊       | 140/496 [00:30<01:07,  5.25it/s]$BLL: possibly delisted; no timezone found\n",
      " 29%|██▊       | 142/496 [00:30<01:07,  5.21it/s]$CTLT: possibly delisted; no timezone found\n",
      " 30%|███       | 150/496 [00:32<01:11,  4.84it/s]$DFS: possibly delisted; no timezone found\n",
      " 33%|███▎      | 162/496 [00:35<01:20,  4.16it/s]$XLNX: possibly delisted; no timezone found\n",
      " 33%|███▎      | 165/496 [00:36<01:16,  4.35it/s]$PKI: possibly delisted; no timezone found\n",
      " 39%|███▉      | 195/496 [00:41<00:51,  5.83it/s]$MRO: possibly delisted; no timezone found\n",
      " 43%|████▎     | 212/496 [00:46<01:19,  3.58it/s]$DISH: possibly delisted; no timezone found\n",
      " 45%|████▌     | 224/496 [00:49<01:03,  4.26it/s]$ANTM: possibly delisted; no timezone found\n",
      " 51%|█████     | 254/496 [00:56<01:06,  3.63it/s]$SIVB: possibly delisted; no timezone found\n",
      " 57%|█████▋    | 283/496 [01:05<01:00,  3.50it/s]$FISV: possibly delisted; no timezone found\n",
      " 62%|██████▏   | 307/496 [01:10<00:35,  5.38it/s]$NLOK: possibly delisted; no timezone found\n",
      " 64%|██████▎   | 316/496 [01:12<00:31,  5.72it/s]$PXD: possibly delisted; no timezone found\n",
      " 73%|███████▎  | 361/496 [01:22<00:35,  3.78it/s]$INFO: possibly delisted; no price data found  (1d 2019-12-01 -> 2023-03-05) (Yahoo error = \"Data doesn't exist for startDate = 1575176400, endDate = 1677992400\")\n",
      " 76%|███████▌  | 376/496 [01:26<00:32,  3.70it/s]$DISCA: possibly delisted; no timezone found\n",
      " 78%|███████▊  | 385/496 [01:27<00:18,  6.06it/s]$DISCK: possibly delisted; no timezone found\n",
      " 78%|███████▊  | 389/496 [01:28<00:24,  4.30it/s]$GPS: possibly delisted; no timezone found\n",
      " 84%|████████▎ | 415/496 [01:35<00:23,  3.46it/s]$ATVI: possibly delisted; no timezone found\n",
      " 89%|████████▉ | 443/496 [01:42<00:12,  4.36it/s]$VIAC: possibly delisted; no timezone found\n",
      " 90%|████████▉ | 445/496 [01:43<00:10,  4.78it/s]$CTXS: possibly delisted; no timezone found\n",
      " 90%|█████████ | 448/496 [01:43<00:07,  6.02it/s]$CERN: possibly delisted; no timezone found\n",
      " 94%|█████████▎| 464/496 [01:47<00:09,  3.54it/s]$TWTR: possibly delisted; no price data found  (1d 2019-12-01 -> 2023-03-05)\n",
      " 98%|█████████▊| 488/496 [01:54<00:02,  2.85it/s]$FB: possibly delisted; no price data found  (1d 2019-12-01 -> 2023-03-05) (Yahoo error = \"Data doesn't exist for startDate = 1575176400, endDate = 1677992400\")\n",
      "100%|██████████| 496/496 [01:56<00:00,  4.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save all the prices in a list from Yahoo Finance API data\n",
    "# Error handle for the failed tickers that don't show up\n",
    "all_prices = []\n",
    "failed_tickers = []\n",
    "\n",
    "for t in tqdm(tickers):\n",
    "    data = get_price_data(t)\n",
    "    if data is not None and not data.empty:\n",
    "        all_prices.append(data)\n",
    "    else:\n",
    "        failed_tickers.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines stock prices into a dataframe\n",
    "price_df = pd.concat(all_prices, ignore_index=True)\n",
    "\n",
    "# Renames and reformats the data into ingestible format\n",
    "price_df.rename(columns={\"Date\": \"date\"}, inplace=True)\n",
    "price_df[\"date\"] = pd.to_datetime(price_df[\"date\"], errors='coerce')\n",
    "\n",
    "# Drop empty rows and sort the values\n",
    "price_df = price_df.dropna().sort_values([\"ticker\", \"date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326cce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378025, 7)\n",
      "                       date       Open       High        Low      Close  \\\n",
      "0 2019-12-02 00:00:00-05:00  77.572081  77.773741  76.842260  77.159157   \n",
      "1 2019-12-03 00:00:00-05:00  76.362129  76.928703  76.026029  76.919098   \n",
      "2 2019-12-04 00:00:00-05:00  77.111139  77.783338  76.995902  77.716118   \n",
      "3 2019-12-05 00:00:00-05:00  77.677706  78.493949  77.303194  78.292290   \n",
      "4 2019-12-06 00:00:00-05:00  78.974097  79.146949  78.570778  78.945290   \n",
      "\n",
      "    Volume ticker  \n",
      "0  1775600      A  \n",
      "1  1978200      A  \n",
      "2  1690900      A  \n",
      "3  1900000      A  \n",
      "4  1783400      A  \n"
     ]
    }
   ],
   "source": [
    "# Ensure the shape and outputs of the new dataframe is accurate\n",
    "print(price_df.shape)\n",
    "print(price_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9283b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes timezone info from the date column\n",
    "price_df[\"date\"] = price_df[\"date\"].dt.tz_localize(None)\n",
    "\n",
    "# Creates a binary target of 1 if the next closing is greater\n",
    "# than today's closing\n",
    "price_df[\"target\"] = (\n",
    "    price_df.groupby(\"ticker\")[\"Close\"].shift(-1) > price_df[\"Close\"]\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the news by date and merging the prices and news data\n",
    "news_grouped[\"date\"] = pd.to_datetime(news_grouped[\"date\"], errors=\"coerce\")\n",
    "merged_df = pd.merge(price_df, news_grouped, on=[\"date\", \"ticker\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad5a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping any null values\n",
    "merged_df = merged_df.dropna(subset=[\"avg_sentiment\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524e9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84052, 10)\n",
      "date                  datetime64[ns]\n",
      "Open                         float64\n",
      "High                         float64\n",
      "Low                          float64\n",
      "Close                        float64\n",
      "Volume                         int64\n",
      "ticker                        object\n",
      "target                         int64\n",
      "combined_headlines            object\n",
      "avg_sentiment                float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>target</th>\n",
       "      <th>combined_headlines</th>\n",
       "      <th>avg_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>155.066666</td>\n",
       "      <td>158.111772</td>\n",
       "      <td>154.200807</td>\n",
       "      <td>157.673981</td>\n",
       "      <td>2154300</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>Factors to Note Ahead of Keysight's (KEYS) Q3 ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>157.343206</td>\n",
       "      <td>157.450223</td>\n",
       "      <td>154.969387</td>\n",
       "      <td>156.545456</td>\n",
       "      <td>2614200</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>Agilent Technologies (A) Q3 Earnings and Reven...</td>\n",
       "      <td>-0.148780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>158.773301</td>\n",
       "      <td>160.874716</td>\n",
       "      <td>157.693408</td>\n",
       "      <td>158.598190</td>\n",
       "      <td>2860900</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>Agilent (A) Q3 Earnings &amp; Revenues Beat Estima...</td>\n",
       "      <td>-0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-19</td>\n",
       "      <td>157.352924</td>\n",
       "      <td>164.493829</td>\n",
       "      <td>157.226446</td>\n",
       "      <td>163.122070</td>\n",
       "      <td>2179600</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>Researchers Develop COVID-19 Severity Screenin...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-08-23</td>\n",
       "      <td>164.834324</td>\n",
       "      <td>165.943417</td>\n",
       "      <td>163.569597</td>\n",
       "      <td>165.388870</td>\n",
       "      <td>2061400</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>Agilent Companion Diagnostic Expands CE-IVD Ma...</td>\n",
       "      <td>-0.306200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        Open        High         Low       Close   Volume ticker  \\\n",
       "0 2021-08-16  155.066666  158.111772  154.200807  157.673981  2154300      A   \n",
       "1 2021-08-17  157.343206  157.450223  154.969387  156.545456  2614200      A   \n",
       "2 2021-08-18  158.773301  160.874716  157.693408  158.598190  2860900      A   \n",
       "3 2021-08-19  157.352924  164.493829  157.226446  163.122070  2179600      A   \n",
       "4 2021-08-23  164.834324  165.943417  163.569597  165.388870  2061400      A   \n",
       "\n",
       "   target                                 combined_headlines  avg_sentiment  \n",
       "0       0  Factors to Note Ahead of Keysight's (KEYS) Q3 ...       0.000000  \n",
       "1       1  Agilent Technologies (A) Q3 Earnings and Reven...      -0.148780  \n",
       "2       1  Agilent (A) Q3 Earnings & Revenues Beat Estima...      -0.041667  \n",
       "3       1  Researchers Develop COVID-19 Severity Screenin...       0.000000  \n",
       "4       1  Agilent Companion Diagnostic Expands CE-IVD Ma...      -0.306200  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that the final dataframe looks right\n",
    "print(merged_df.shape)\n",
    "print(merged_df.dtypes)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de171af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    462.000000\n",
       "mean     181.930736\n",
       "std       24.579579\n",
       "min       88.000000\n",
       "25%      167.250000\n",
       "50%      185.000000\n",
       "75%      199.000000\n",
       "max      256.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensuring data quality seems appropriate\n",
    "merged_df[\"ticker\"].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a38b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved the merged data in a new csv\n",
    "merged_df.to_csv(\"data/processed/merged_news_stock_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
